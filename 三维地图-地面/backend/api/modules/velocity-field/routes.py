"""
é€Ÿåº¦åœºå¯è§†åŒ– - APIè·¯ç”±
ä»4Dé¡¹ç›®è¿ç§»è€Œæ¥,æä¾›å®Œæ•´çš„åœ°ä¸‹é€Ÿåº¦åœºæ•°æ®é›†è®¿é—®æ¥å£
"""
from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import FileResponse
from pathlib import Path
import json
import h5py
import numpy as np
from datetime import datetime
import os

# åˆ›å»ºè·¯ç”±å™¨,ä½¿ç”¨æ ‡å‡†çš„/apiå‰ç¼€
router = APIRouter(prefix="/api", tags=["velocity-field"])

# æ•°æ®ç›®å½•é…ç½®
DATASETS_DIR = Path(__file__).parent.parent.parent.parent.parent / "data" / "datasets"

# æ—¥å¿—é…ç½®
DEBUG = os.getenv('DEBUG', 'true').lower() == 'true'

# ============================================================================
# æ—¥å¿—å·¥å…·å‡½æ•°
# ============================================================================

def log_debug(msg):
    """è°ƒè¯•æ—¥å¿— - ä»…åœ¨DEBUG=trueæ—¶è¾“å‡º"""
    if DEBUG:
        print(f"[DEBUG] {datetime.now().strftime('%H:%M:%S')} {msg}")

def log_info(msg):
    """ä¿¡æ¯æ—¥å¿— - å§‹ç»ˆè¾“å‡º"""
    print(f"[INFO]  {datetime.now().strftime('%H:%M:%S')} {msg}")

def log_error(msg):
    """é”™è¯¯æ—¥å¿— - å§‹ç»ˆè¾“å‡º"""
    print(f"[ERROR] {datetime.now().strftime('%H:%M:%S')} {msg}")

# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def get_dataset_path(dataset_name: str) -> Path:
    """è·å–æ•°æ®é›†è·¯å¾„"""
    dataset_path = DATASETS_DIR / dataset_name
    if not dataset_path.exists():
        raise HTTPException(status_code=404, detail=f"æ•°æ®é›†ä¸å­˜åœ¨: {dataset_name}")
    return dataset_path


def load_dataset_config(dataset_name: str) -> dict:
    """åŠ è½½æ•°æ®é›†é…ç½®"""
    config_path = get_dataset_path(dataset_name) / "dataset_config.json"
    if not config_path.exists():
        raise HTTPException(status_code=404, detail=f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {dataset_name}")
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


# ============================================================================
# æ•°æ®é›†ç®¡ç†API
# ============================================================================

@router.get("/datasets")
async def list_datasets():
    """è·å–æ‰€æœ‰æ•°æ®é›†åˆ—è¡¨"""
    try:
        index_path = DATASETS_DIR / "datasets_index.json"
        if not index_path.exists():
            return {
                'success': True,
                'data': {'datasets': [], 'count': 0}
            }

        with open(index_path, 'r', encoding='utf-8') as f:
            index = json.load(f)

        return {
            'success': True,
            'data': index
        }
    except Exception as e:
        log_error(f"è·å–æ•°æ®é›†åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/datasets/{dataset_name}/config")
async def get_dataset_config(dataset_name: str):
    """è·å–æ•°æ®é›†é…ç½®ä¿¡æ¯"""
    try:
        config = load_dataset_config(dataset_name)
        return {
            'success': True,
            'data': config
        }
    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–æ•°æ®é›†é…ç½®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/datasets/{dataset_name}/ui-config")
async def get_ui_config(dataset_name: str):
    """è·å–æ•°æ®é›†çš„UIé…ç½®æ–‡ä»¶"""
    try:
        dataset_path = get_dataset_path(dataset_name)
        ui_config_path = dataset_path / "ui-config.json"

        if not ui_config_path.exists():
            raise HTTPException(
                status_code=404,
                detail=f'UIé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {dataset_name}/ui-config.json'
            )

        with open(ui_config_path, 'r', encoding='utf-8') as f:
            ui_config = json.load(f)

        return ui_config

    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–UIé…ç½®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# é€Ÿåº¦åœºæ•°æ®API
# ============================================================================

@router.get("/datasets/{dataset_name}/velocity/metadata")
async def get_velocity_metadata(dataset_name: str):
    """è·å–é€Ÿåº¦åœºå…ƒæ•°æ®ï¼ˆç½‘æ ¼ä¿¡æ¯ã€æ•°æ®èŒƒå›´ç­‰ï¼‰"""
    try:
        dataset_path = get_dataset_path(dataset_name)
        h5_path = dataset_path / "velocity_model.h5"

        if not h5_path.exists():
            raise HTTPException(status_code=404, detail="é€Ÿåº¦åœºæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")

        with h5py.File(h5_path, 'r') as f:
            metadata = {
                'grid': {
                    'longitude': f['grid/lon'][:].tolist(),
                    'latitude': f['grid/lat'][:].tolist(),
                    'depth': f['grid/depth'][:].tolist(),
                    'shape': {
                        'lon': len(f['grid/lon']),
                        'lat': len(f['grid/lat']),
                        'depth': len(f['grid/depth'])
                    }
                },
                'properties': ['vp', 'vs', 'vp_vs_ratio'],
                'statistics': {}
            }

            # è¯»å–ç»Ÿè®¡ä¿¡æ¯
            if 'statistics' in f:
                for prop in ['vp', 'vs', 'vp_vs_ratio']:
                    metadata['statistics'][prop] = {
                        'min': float(f[f'statistics/{prop}_min'][()]),
                        'max': float(f[f'statistics/{prop}_max'][()]),
                        'mean': float(f[f'statistics/{prop}_mean'][()])
                    }

        return {
            'success': True,
            'data': metadata
        }

    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–é€Ÿåº¦åœºå…ƒæ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/datasets/{dataset_name}/velocity/data")
async def get_velocity_data(
    dataset_name: str,
    property: str = Query(default='vp', description="å±æ€§åç§°: vp, vs, vp_vs_ratio")
):
    """è·å–é€Ÿåº¦åœºæ•°æ®ï¼ˆä½“æ•°æ®ï¼‰"""
    try:
        dataset_path = get_dataset_path(dataset_name)
        h5_path = dataset_path / "velocity_model.h5"

        if not h5_path.exists():
            raise HTTPException(status_code=404, detail="é€Ÿåº¦åœºæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")

        with h5py.File(h5_path, 'r') as f:
            # è¯»å–æ•°æ®
            data = f[f'properties/{property}'][:]

            # è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆç”¨äºJSONåºåˆ—åŒ–ï¼‰
            # æ•°æ®å½¢çŠ¶: (depth, lat, lon)
            response = {
                'property': property,
                'shape': list(data.shape),
                'data': data.flatten().tolist(),  # å±•å¹³ä¸º1Dæ•°ç»„
                'data_type': 'float32'
            }

        return {
            'success': True,
            'data': response
        }

    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–é€Ÿåº¦åœºæ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/datasets/{dataset_name}/velocity/slice")
async def get_velocity_slice(
    dataset_name: str,
    property: str = Query(default='vp', description="å±æ€§åç§°: vp, vs, vp_vs_ratio"),
    axis: str = Query(default='depth', description="åˆ‡ç‰‡è½´: depth, lat, lon"),
    index: int = Query(default=0, description="åˆ‡ç‰‡ç´¢å¼•")
):
    """è·å–é€Ÿåº¦åœºåˆ‡ç‰‡ï¼ˆç”¨äº2Då¯è§†åŒ–æˆ–ä¼˜åŒ–ä¼ è¾“ï¼‰"""
    try:
        dataset_path = get_dataset_path(dataset_name)
        h5_path = dataset_path / "velocity_model.h5"

        if not h5_path.exists():
            raise HTTPException(status_code=404, detail="é€Ÿåº¦åœºæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")

        with h5py.File(h5_path, 'r') as f:
            data = f[f'properties/{property}'][:]

            # æ ¹æ®è½´é€‰æ‹©åˆ‡ç‰‡
            if axis == 'depth':
                slice_data = data[index, :, :]
            elif axis == 'lat':
                slice_data = data[:, index, :]
            elif axis == 'lon':
                slice_data = data[:, :, index]
            else:
                raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„è½´: {axis}")

            response = {
                'property': property,
                'axis': axis,
                'index': index,
                'shape': list(slice_data.shape),
                'data': slice_data.flatten().tolist()
            }

        return {
            'success': True,
            'data': response
        }

    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–é€Ÿåº¦åœºåˆ‡ç‰‡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# åœ°éœ‡æ•°æ®API
# ============================================================================

@router.get("/datasets/{dataset_name}/earthquakes")
async def get_earthquakes(
    dataset_name: str,
    min_mag: float = Query(default=2.0, description="æœ€å°éœ‡çº§"),
    max_mag: float = Query(default=10.0, description="æœ€å¤§éœ‡çº§"),
    start_time: str = Query(default=None, description="å¼€å§‹æ—¶é—´"),
    end_time: str = Query(default=None, description="ç»“æŸæ—¶é—´"),
    limit: int = Query(default=50000, description="è¿”å›æ•°é‡é™åˆ¶")
):
    """è·å–åœ°éœ‡ç›®å½•æ•°æ®"""
    try:
        dataset_path = get_dataset_path(dataset_name)
        json_path = dataset_path / "earthquakes_filtered.json"

        if not json_path.exists():
            raise HTTPException(status_code=404, detail="åœ°éœ‡æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")

        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        earthquakes = data['earthquakes']

        # ç­›é€‰
        filtered = []
        for eq in earthquakes:
            if eq['magnitude'] < min_mag or eq['magnitude'] > max_mag:
                continue
            if start_time and eq['time'] < start_time:
                continue
            if end_time and eq['time'] > end_time:
                continue
            filtered.append(eq)
            if len(filtered) >= limit:
                break

        return {
            'success': True,
            'data': {
                'metadata': data['metadata'],
                'earthquakes': filtered,
                'total_returned': len(filtered)
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–åœ°éœ‡æ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# æ–­å±‚æ•°æ®API
# ============================================================================

@router.get("/datasets/{dataset_name}/faults")
async def get_faults(dataset_name: str):
    """è·å–æ–­å±‚æ•°æ®"""
    try:
        dataset_path = get_dataset_path(dataset_name)
        json_path = dataset_path / "faults_clipped.json"

        if not json_path.exists():
            raise HTTPException(status_code=404, detail="æ–­å±‚æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")

        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        return {
            'success': True,
            'data': data
        }

    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–æ–­å±‚æ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# éœ‡æºæœºåˆ¶è§£API
# ============================================================================

@router.get("/datasets/{dataset_name}/focal-mechanisms")
async def get_focal_mechanisms(
    dataset_name: str,
    min_mag: float = Query(default=4.0, description="æœ€å°éœ‡çº§"),
    limit: int = Query(default=2000, description="è¿”å›æ•°é‡é™åˆ¶")
):
    """è·å–éœ‡æºæœºåˆ¶è§£æ•°æ®"""
    try:
        dataset_path = get_dataset_path(dataset_name)
        json_path = dataset_path / "focal_mechanisms.json"

        if not json_path.exists():
            raise HTTPException(status_code=404, detail="éœ‡æºæœºåˆ¶è§£æ–‡ä»¶ä¸å­˜åœ¨")

        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        mechanisms = data['mechanisms']

        # ç­›é€‰
        filtered = [m for m in mechanisms if m['magnitude'] >= min_mag][:limit]

        return {
            'success': True,
            'data': {
                'metadata': data['metadata'],
                'mechanisms': filtered,
                'total_returned': len(filtered)
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–éœ‡æºæœºåˆ¶è§£å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# åœ°å½¢æ•°æ®API
# ============================================================================

@router.get("/datasets/{dataset_name}/terrain/config")
async def get_terrain_config(dataset_name: str):
    """è·å–åœ°å½¢é…ç½®ä¿¡æ¯"""
    try:
        dataset_path = get_dataset_path(dataset_name)
        config_path = dataset_path / "terrain" / "terrain_config.json"

        if not config_path.exists():
            raise HTTPException(status_code=404, detail="åœ°å½¢é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")

        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        return {
            'success': True,
            'data': config
        }

    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–åœ°å½¢é…ç½®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/datasets/{dataset_name}/terrain/dem")
async def get_terrain_dem(dataset_name: str):
    """è·å–åœ°å½¢DEMæ•°æ®ï¼ˆäºŒè¿›åˆ¶æ–‡ä»¶ï¼‰"""
    try:
        dataset_path = get_dataset_path(dataset_name)
        dem_path = dataset_path / "terrain" / "dem" / "terrain.bin"

        if not dem_path.exists():
            raise HTTPException(status_code=404, detail="DEMæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")

        return FileResponse(
            path=str(dem_path),
            media_type='application/octet-stream',
            filename='terrain.bin'
        )

    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–DEMæ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/datasets/{dataset_name}/terrain/texture")
async def get_terrain_texture(dataset_name: str):
    """è·å–åœ°å½¢çº¹ç†å›¾åƒ"""
    try:
        dataset_path = get_dataset_path(dataset_name)
        texture_path = dataset_path / "terrain" / "image" / "terrain_texture.png"

        if not texture_path.exists():
            raise HTTPException(status_code=404, detail="åœ°å½¢çº¹ç†æ–‡ä»¶ä¸å­˜åœ¨")

        return FileResponse(
            path=str(texture_path),
            media_type='image/png',
            filename='terrain_texture.png'
        )

    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–åœ°å½¢çº¹ç†å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# åœ°è¡¨å›¾å±‚API (åŸå¸‚ã€å°ç«™ã€æ–­è£‚çº¿ã€è¾¹ç•Œ)
# ============================================================================

@router.get("/datasets/{dataset_name}/layers/{layer_name}")
async def get_surface_layer(dataset_name: str, layer_name: str):
    """è·å–åœ°è¡¨å›¾å±‚æ•°æ® (GeoJSONæ ¼å¼)

    æ”¯æŒçš„å›¾å±‚:
    - cities: åŸå¸‚ç‚¹ä½æ•°æ®
    - stations: å°ç«™æ•°æ®
    - fault_lines: æ–­è£‚çº¿æ•°æ®
    - boundary_national: å›½ç•Œæ•°æ®
    - boundary_province: çœç•Œæ•°æ®
    - boundary_city: å¸‚ç•Œæ•°æ®
    """
    try:
        dataset_path = get_dataset_path(dataset_name)
        layers_dir = dataset_path / "layers"

        # å…è®¸çš„å›¾å±‚æ–‡ä»¶
        allowed_layers = {
            'cities': 'cities.json',
            'stations': 'stations.json',
            'fault_lines': 'fault_lines.json',
            'boundary_national': 'boundary_national.json',
            'boundary_province': 'boundary_province.json',
            'boundary_city': 'boundary_city.json'
        }

        if layer_name not in allowed_layers:
            raise HTTPException(
                status_code=400,
                detail=f'æœªçŸ¥å›¾å±‚ç±»å‹: {layer_name}'
            )

        layer_file = layers_dir / allowed_layers[layer_name]

        # Debug: æ‰“å°å®é™…è¯»å–çš„æ–‡ä»¶è·¯å¾„å’Œfeaturesæ•°é‡
        log_debug(f"ğŸ“„ è¯»å–å›¾å±‚æ–‡ä»¶: {layer_file.name}")
        log_debug(f"   ç»å¯¹è·¯å¾„: {layer_file.absolute()}")
        log_debug(f"   æ–‡ä»¶å¤§å°: {layer_file.stat().st_size if layer_file.exists() else 'N/A'} bytes")

        if not layer_file.exists():
            log_error(f"å›¾å±‚æ–‡ä»¶ä¸å­˜åœ¨: {layer_file.name}")
            raise HTTPException(
                status_code=404,
                detail=f'å›¾å±‚æ–‡ä»¶ä¸å­˜åœ¨: {layer_file.name}'
            )

        # è¯»å–å¹¶è¿”å›GeoJSONæ•°æ®
        with open(layer_file, 'r', encoding='utf-8') as f:
            layer_data = json.load(f)
            features = layer_data.get('features', [])
            log_debug(f"   ç‰¹å¾æ•°é‡: {len(features)}")
            if features:
                geom = features[0]['geometry']
                log_debug(f"   ğŸ“ è¯»å–åå‡ ä½•ç±»å‹: {geom['type']}")
                log_debug(f"   ğŸ“ åæ ‡æ•°é‡: {len(geom['coordinates'])}")

        return {
            'success': True,
            'data': layer_data
        }

    except HTTPException:
        raise
    except Exception as e:
        log_error(f"è·å–å›¾å±‚æ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# å¥åº·æ£€æŸ¥
# ============================================================================

@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        'success': True,
        'status': 'healthy',
        'message': 'é€Ÿåº¦åœºå¯è§†åŒ–æ¨¡å—è¿è¡Œæ­£å¸¸'
    }
